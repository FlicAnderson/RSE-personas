{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb70c8d",
   "metadata": {},
   "source": [
    "# GitHub Commit Data: Getting, Processing, Analysing Pipeline.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559655cc",
   "metadata": {},
   "source": [
    "This notebook will:  \n",
    "    - explore commit data (from GitHub API) processing and analysis  \n",
    "    - act as documentation about how the project commit data is being obtained, reshaped and analysed.  \n",
    "    - explain the interactions between different project functions and scripts  \n",
    "    - clarify what commit data is stored and where  \n",
    "    - prove why these steps are necessary for generating the dataset which will be used for Research Assistant Personas research work  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6af51",
   "metadata": {},
   "source": [
    "## Overall plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb58f10",
   "metadata": {},
   "source": [
    "Aims:   \n",
    "\n",
    "I need to obtain and analyse commit data for given github repositories of research software to be able to explore the ways in which the developers in those research software projects engage and interact with the codebase and associated GH development and project management tools.\n",
    "\n",
    "I expect that different developers will fall into at least two to three defineable categories of behaviours, and that analysis of commits will be crucial to being able to: a) describe these categories, and b) how to assign individual developers to those different categories, on the basis of their interactions with the repo.  \n",
    "\n",
    "By exploring the data from many different RS repositories using scripts, I should be able to gather a large dataset to investigate these hypotheses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838340c",
   "metadata": {},
   "source": [
    "Overview:  \n",
    "\n",
    "\n",
    "00) Setup, imports, logging  \n",
    "\n",
    "01) Get RS repo name(s) for study (inclusion/exclusion steps)   \n",
    "02) Check whether current data already exists; if so, use that      \n",
    "\n",
    "03) Query API for repo(s) commits data   \n",
    "\n",
    "04) Save out raw commits json for repo(s)  \n",
    "05) Convert data to pandas format for analysis  \n",
    "\n",
    "06) Calculate commits summary stats for repo(s)  \n",
    "\n",
    "07) Slice commits data by commit author  \n",
    "\n",
    "08) Calculate commits summary stats for author(s)  \n",
    "\n",
    "09) Compare author commits stats to repo commits stats; looking for outliers or differences in terms of frequency of commits, change size, files changed, file types changed (vasilescu_variations_2014), key words frequencies (hattori_nature_2008), etc.  \n",
    "\n",
    "10) Report findings  \n",
    "11) Return data in useful format for subsequent analyses / visualisation  \n",
    "12) Save out data \n",
    "\n",
    "13) Visualisation of commits data for a) dataset of repo(s); b) individual repo(s); c) individual authors (optional, perhaps only where outliers or interesting differences show up); \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2eec9",
   "metadata": {},
   "source": [
    "## File system Organisation  \n",
    "\n",
    "REPO ROOT:   \n",
    "`/` (coding-smart repo root)   \n",
    "\n",
    "DOCS FOLDERS:    \n",
    "`/docs/` - currently this holds .jpg files of UML diagrams referred to in the overall repo readme.   \n",
    "\n",
    "OUTPUT FOLDERS:   \n",
    "`/data/` - holds .csv files of data obtained from GH API calls.  \n",
    "`/logs/` - holds .txt logfiles with name format `[functionname or scriptname]_(NOTEBOOK)_logs.txt`\n",
    " where 'NOTEBOOK' is optional and relates to output logs generated by jupyter notebook function runs.  \n",
    "`/images/` - holds .png files generated by python plotting and visualisation of the GH data.    \n",
    "\n",
    "SOURCE CODE FOLDERS:    \n",
    "`/utilities/` - contains utility functions and scripts of general usability   \n",
    "`/githubanalysis/` -  contains functions and scripts relating to the github API and subsequent data operations     \n",
    "`/zenodocode/` - contains functions and scripts relating to zenodo API for identifying RS repos' github repo names      \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac7397",
   "metadata": {},
   "source": [
    "## Notebook Imports and Setup  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6910938c",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "Ensure you are in the `coding-smart-github` conda environment and have the following packages installed in your environment which match the `requirements.txt` file in the coding-smart repository.  \n",
    "\n",
    "### Github Authentication \n",
    "\n",
    "Create a classic access token via [Github Authentication Settings](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token#creating-a-personal-access-token-classic) and create a file called `config.cfg` in the `githubanalysis/` folder with the following content: \n",
    "```bash\n",
    "[ACCESS]\n",
    "token = <your-access-token>\n",
    "```\n",
    "Ensure you've pasted in your token, but leave `[ACCESS]` and `token = `."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2283a1",
   "metadata": {},
   "source": [
    "## Import python packages required for notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49917e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import configparser\n",
    "from github import Github\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e0b569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up github access token with github package: \n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.cfg')\n",
    "config.sections()\n",
    "\n",
    "access_token = config['ACCESS']['token']\n",
    "g = Github(access_token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53454617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import existing scripts from repo for use in notebook   \n",
    "\n",
    "# logging:  \n",
    "\n",
    "# GH API access/querying  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833fd45",
   "metadata": {},
   "source": [
    "05) Convert data to pandas format for analysis  \n",
    "\n",
    "06) Calculate commits summary stats for repo(s)  \n",
    "\n",
    "07) Slice commits data by commit author  \n",
    "\n",
    "08) Calculate commits summary stats for author(s)  \n",
    "\n",
    "09) Compare author commits stats to repo commits stats; looking for outliers or differences in terms of frequency of commits, change size, files changed, file types changed (vasilescu_variations_2014), key words frequencies (hattori_nature_2008), etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a55e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in commits data from an existing data file  \n",
    "\n",
    "# check it's in pandas format (05)  \n",
    "\n",
    "# calculate a summary stat (e.g. changesize of commit; )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1fc82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of commits for repo of repo_name\n",
    "\n",
    "import requests\n",
    "from urllib.parse import parse_qs, urlparse\n",
    "\n",
    "class CommitsCount: \n",
    "    def get_commits_count(self, repo_name: str) -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of commits to a GitHub repository.\n",
    "        \"\"\"\n",
    "        url = f\"https://api.github.com/repos/{repo_name}/commits?per_page=1\"\n",
    "        r = requests.get(url)\n",
    "        links = r.links\n",
    "        rel_last_link_url = urlparse(links[\"last\"][\"url\"])\n",
    "        rel_last_link_url_args = parse_qs(rel_last_link_url.query)\n",
    "        rel_last_link_url_page_arg = rel_last_link_url_args[\"page\"][0]\n",
    "        commits_count = int(rel_last_link_url_page_arg)\n",
    "        return commits_count\n",
    "    # code via https://brianli.com/2022/07/python-get-number-of-commits-github-repository/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183341ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of commits for 1 named (currently hardcoded) repo\n",
    "c = CommitsCount()\n",
    "c.get_commits_count(repo_name=\"JeschkeLab/DeerLab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "467e4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import githubanalysis.processing.get_repo_connection as ghconn\n",
    "# repo_con = ghconn.get_repo_connection(repo_name, config_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28d7854f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_all_pages_commits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m config_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../githubanalysis/config.cfg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#all_commits = getallcommits.get_all_pages_commits(repo_name, config_path='../../githubanalysis/config.cfg', per_pg=100, verbose=True)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mget_all_pages_commits\u001b[49m(repo_name\u001b[38;5;241m=\u001b[39mrepo_name, config_path\u001b[38;5;241m=\u001b[39mconfig_path, per_pg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_all_pages_commits' is not defined"
     ]
    }
   ],
   "source": [
    "# check current function(s) for getting all commits for a repo   \n",
    "import githubanalysis.processing.get_all_pages_commits\n",
    "\n",
    "repo_name = \"JeschkeLab/DeerLab\"\n",
    "config_path='../../githubanalysis/config.cfg'\n",
    "\n",
    "#all_commits = getallcommits.get_all_pages_commits(repo_name, config_path='../../githubanalysis/config.cfg', per_pg=100, verbose=True)\n",
    "\n",
    "get_all_pages_commits(repo_name=repo_name, config_path=config_path, per_pg=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c051f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities.get_default_logger as loggit\n",
    "import utilities.chunker as chunker\n",
    "\n",
    "import githubanalysis.processing.get_all_pages_commits \n",
    "from githubanalysis.processing.get_all_pages_commits import CommitsGetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763d1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = 'JeschkeLab/DeerLab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0df06f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:Something failed in getting commits for repo JeschkeLab/DeerLab: local variable 'i' referenced before assignment. Traceback: Traceback (most recent call last):\n",
      "  File \"/home/eidf103/eidf103/flic/clonezone/coding-smart/githubanalysis/processing/get_all_pages_commits.py\", line 98, in get_all_pages_commits\n",
      "    commits_query = f\"https://api.github.com/repos/{repo_name}/commits?per_page={per_pg}&page={i}\"\n",
      "UnboundLocalError: local variable 'i' referenced before assignment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logger = loggit.get_default_logger(console=True, set_level_to='DEBUG', log_name='../../logs/get_all_pages_issues_NOTEBOOK_logs.txt')  \n",
    "#issues_getter = IssueGetter(logger)\n",
    "#iss_df = issues_getter.get_all_pages_issues(repo_name=item, config_path='../../githubanalysis/config.cfg', out_filename='all-issues', write_out_location='../../data/')\n",
    "\n",
    "logger = loggit.get_default_logger(console=True, set_level_to='DEBUG', log_name='../../logs/get_all_pages_commits_NOTEBOOK_logs.txt')  \n",
    "commits_getter = CommitsGetter(logger)\n",
    "\n",
    "coms_df = commits_getter.get_all_pages_commits(repo_name=repo_name, config_path='../../githubanalysis/config.cfg', out_filename='all-commits', write_out_location='../../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9441d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12753dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2626539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e535bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369165f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e173200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from all commits for 1 repo .csv  \n",
    "\n",
    "import gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ec2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ad8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc6484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67c9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2282140d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
