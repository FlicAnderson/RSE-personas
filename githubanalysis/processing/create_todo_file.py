"""Create todo file from github urls for processing."""

import sys
import logging
import pandas as pd
from datetime import datetime

import utilities.get_default_logger as loggit
import githubanalysis.processing.repo_name_clean as getreponame


class TODOMaker:
    # if not given a better option, use my default settings for logging
    logger: logging.Logger

    def __init__(self, logger: logging.Logger = None) -> None:
        if logger is None:
            self.logger = loggit.get_default_logger(
                console=False,
                set_level_to="INFO",
                log_name="logs/create_todo_file_logs.txt",
            )
        else:
            self.logger = logger

    def create_todo_file(
        self,
        in_filename="gh_urls",
        read_in_location="data/",
        out_filename="todo",
        write_out_location="data/",
    ):
        """
        This function should generate a working todo file
        from a data file of zenodo IDs and GitHub URLs.
        This will be output to csv.

        :param in_filename: name of CSV file to read in, excluding file extension. Default = "gh_urls".
        :type: str
        :param read_in_location: path of Github URLs file as string. Default = "data/"
        :type: str
        :param out_filename: name to include in write out filename. Saves as CSV. Default="todo".
        :type: str
        :param write_out_location: desired file location path as string. Default = "data/"
        :type: str
        :returns: gh_urls_df
        :type: pd.DataFrame with 14 columns: ZenodoID, GitHubURL and 13 task status columns.

        Example:

        $  python githubanalysis/processing/create_todo_file.py data/gh_urls_2024-02-05.csv

        INFO:Using commandline argument data/gh_urls_2024-02-05.csv as input file of Zenodo IDs to retrieve GH URLs for. Entered as: data/gh_urls_2024-02-05.csv
        INFO:Written out 1062 github url records to TODO file data/todo_2024-02-06.csv with 13 columns.

        """

        # read-in file setup (accept commandline input for gh_urls file if any)
        if len(sys.argv) == 2:
            gh_urls_file_extra_info = sys.argv[
                1
            ]  # use second argv (user-provided by commandline)

            if not isinstance(gh_urls_file_extra_info, str):
                raise TypeError(
                    "Ensure argument is a file location and name in string format (e.g. 'data/gh_urls.csv')"
                )

            self.logger.info(
                f"Using commandline argument {gh_urls_file_extra_info} as input file of GitHub URLS to set up TODO file from. Entered as: {sys.argv[1]}"
            )
        else:
            # default location: data/gh_urls.csv
            gh_file = f"{read_in_location}{in_filename}.csv"
            current_date_info = datetime.now().strftime(
                "%Y-%m-%d"
            )  # run this at start of script not in loop to avoid midnight/long-run issues
            gh_urls_file_extra_info = f"{gh_file}_{current_date_info}.csv"

        # write-out file setup
        # get date for generating extra filename info
        current_date_info = datetime.now().strftime(
            "%Y-%m-%d"
        )  # run this at start of script not in loop to avoid midnight/long-run issues
        write_out = f"{write_out_location}{out_filename}"
        write_out_extra_info = f"{write_out}_{current_date_info}.csv"

        # read in data/gh_urls.csv file
        # ... get ZenodoID and GitHubURL for each record in gh_urls*.csv
        gh_urls_df = pd.DataFrame()
        try:
            gh_urls_df = pd.read_csv(
                gh_urls_file_extra_info,
                header=0,
                usecols=["ZenodoID", "GitHubURL"],
                dtype={"ZenodoID": "Int64", "GitHubURL": "str"},
            )
            self.logger.debug(
                f"Read in {len(gh_urls_df.index)} records to convert to TODO file."
            )
        except Exception as e:
            self.logger.error(
                f"There's been an exception while trying to read back in data generated by get_gh_urls() from {gh_urls_file_extra_info}: {e}"
            )

        # pull out usable repo name from url string
        try:
            gh_urls_df["repo_name"] = gh_urls_df[["GitHubURL"]].apply(
                lambda x: [getreponame.repo_name_clean(x) for x in x]
            )
        except Exception as e:
            self.logger.error(
                f"Issue while trying to apply repo_name_clean() to repo urls: {e}"
            )

        # repo_data_df['assigned_devs'] = repo_data_df[['assignees']].applymap(lambda x: [x.get('login') for x in x])

        # add task columns with 'Not started' info
        nowtime = datetime.now().strftime("%Y-%m-%d, %H:%M")
        gh_urls_df["check_uses_tickets"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_number_tickets"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_number_contributors"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_uses_PRs"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_number_PRs"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_repo_age"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_repo_active"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_number_commits"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_repo_license"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_repo_visibility"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )
        gh_urls_df["check_repo_language"] = (
            f"NOT Started @ {datetime.now().strftime('%Y-%m-%d, %H:%M')}"
        )

        # write out todo file (use added date filename)
        try:
            gh_urls_df.to_csv(write_out_extra_info, mode="w", index=False, header=True)
            self.logger.info(
                f"Written out {len(gh_urls_df.index)} github url records to TODO file {write_out_extra_info} with {gh_urls_df.shape[1]} columns."
            )
        except Exception as e:
            self.logger.error(
                f"There's been an exception while trying to write out todo list generated from {gh_urls_file_extra_info} into {write_out_extra_info}: {e}"
            )

        return gh_urls_df


# this bit
if __name__ == "__main__":
    """
    get github URLs info, add task columns
    write these out to todo file csv
    """
    logger = loggit.get_default_logger(
        console=True, set_level_to="DEBUG", log_name="logs/create_todo_file_logs.txt"
    )

    todo_maker = TODOMaker(logger)

    gh_urls_df = pd.DataFrame()
    try:
        todo_maker.create_todo_file(
            in_filename="gh_urls",
            read_in_location="data/",
            out_filename="todo",
            write_out_location="data/",
        )
    except Exception as e:
        logger.error(f"There's been an exception in running create_todo_file(): {e}")
